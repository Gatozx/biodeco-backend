import os
from dotenv import load_dotenv
from openai import OpenAI
import replicate  # <--- IMPORTAMOS LA NUEVA LIBRERÃA

# 1. CARGAMOS LAS VARIABLES
load_dotenv()

# --- CONFIGURACIÃ“N DE LOS CLIENTES ---

# Cliente A: EL CEREBRO (DeepSeek)
client_deepseek = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"),
    base_url="https://api.deepseek.com"
)

# Nota: Replicate se configura solo automÃ¡ticamente al leer 
# la variable REPLICATE_API_TOKEN del archivo .env

# --- MEMORIA DEL TERAPEUTA ---
SYSTEM_PROMPT = """
Eres un terapeuta experto en BiodecodificaciÃ³n. Tu objetivo es dialogar,
hacer preguntas cortas para indagar y encontrar el conflicto emocional.
SÃ© cÃ¡lido y empÃ¡tico.
"""
historial = [{"role": "system", "content": SYSTEM_PROMPT}]

# --- FUNCIONES ---

def transcribir_audio_replicate(ruta_archivo):
    print("ğŸ¤ Conectando con Replicate para buscar la Ãºltima versiÃ³n de Whisper...")
    try:
        input_audio = open(ruta_archivo, "rb")
        
        # 1. BUSCAMOS LA VERSIÃ“N MÃS RECIENTE AUTOMÃTICAMENTE
        # En lugar de pegar el cÃ³digo raro, le pedimos a Replicate:
        # "Â¿CuÃ¡l es la Ãºltima versiÃ³n de openai/whisper?"
        model = replicate.models.get("openai/whisper")
        latest_version = model.versions.list()[0] # Tomamos la primera de la lista (la mÃ¡s nueva)
        
        print(f"   (Usando versiÃ³n: {latest_version.id[:10]}...)")

        # 2. EJECUTAMOS ESA VERSIÃ“N
        output = replicate.run(
            f"openai/whisper:{latest_version.id}", # Usamos el ID que acabamos de encontrar
            input={
                "audio": input_audio,
                "model": "large-v3",
                "language": "es",    
                "translate": False,
                "temperature": 0
            }
        )
        
        # 3. PROCESAMOS EL RESULTADO
        texto_detectado = ""
        if isinstance(output, dict) and "text" in output:
             texto_detectado = output["text"]
        else:
             texto_detectado = str(output)

        print(f"ğŸ“ El paciente dijo: {texto_detectado}")
        return texto_detectado

    except Exception as e:
        print(f"âŒ Error en Replicate: {e}")
        return ""
    
def pensar_respuesta(texto_usuario):
    print("ğŸ§  Analizando conflicto (DeepSeek)...")
    
    # Agregamos lo que dijo el usuario a la memoria
    historial.append({"role": "user", "content": texto_usuario})
    
    try:
        response = client_deepseek.chat.completions.create(
            model="deepseek-chat",
            messages=historial,
            temperature=0.7
        )
        respuesta = response.choices[0].message.content
        
        # Agregamos la respuesta de la IA a la memoria
        historial.append({"role": "assistant", "content": respuesta})
        return respuesta
    except Exception as e:
        return f"Error pensando: {e}"

# --- EJECUCIÃ“N ---
if __name__ == "__main__":
    print("--- SISTEMA: REPLICATE (OÃDO) + DEEPSEEK (CEREBRO) ---")
    
    archivo_audio = "prueba.mp3" 
    
    # Verificamos que tengas el archivo listo
    if os.path.exists(archivo_audio):
        
        # 1. El paciente habla (Audio -> Texto)
        texto_transcrito = transcribir_audio_replicate(archivo_audio)
        
        if texto_transcrito:
            # 2. El terapeuta piensa (Texto -> Texto)
            respuesta = pensar_respuesta(texto_transcrito)
            
            print(f"\nğŸ‘©â€âš•ï¸ Terapeuta IA: {respuesta}")
            
            # (AquÃ­ irÃ­a el paso 3: ElevenLabs para convertir la respuesta en voz)
    else:
        print(f"âš ï¸ ATENCIÃ“N: No encontrÃ© '{archivo_audio}'.")
        print("Graba una nota de voz con tu celular, pÃ¡sala a esta carpeta y llÃ¡mala 'prueba.mp3'")