import os
import replicate
from dotenv import load_dotenv
from openai import OpenAI  # Usamos la librer√≠a de OpenAI para conectar con DeepSeek

# Cargar variables de entorno (.env)
load_dotenv()

# Configuraci√≥n del cliente DeepSeek
# Aseg√∫rate de que tu .env tenga DEEPSEEK_API_KEY
client = OpenAI(
    api_key=os.getenv("DEEPSEEK_API_KEY"), 
    base_url="https://api.deepseek.com"
)

def formatear_transcripcion(salida_replicate):
    """
    Funci√≥n auxiliar para convertir la salida compleja de la IA (JSON)
    en un texto legible tipo guion de teatro.
    """
    texto_formateado = ""
    
    # Verificamos si la salida tiene segmentos (estructura habitual de WhisperX/Diarization)
    # Nota: La estructura puede variar, pero generalmente es una lista de segmentos bajo 'segments'
    try:
        segments = salida_replicate.get('segments', [])
        
        for segment in segments:
            # Replicate suele devolver 'SPEAKER_00', 'SPEAKER_01'. 
            # Tomamos el nombre del hablante y el texto.
            speaker = segment.get('speaker', 'Desconocido')
            text = segment.get('text', '')
            
            # Limpiamos espacios extra
            texto_formateado += f"{speaker}: {text.strip()}\n"
            
        return texto_formateado
        
    except Exception as e:
        print(f"Advertencia al formatear: {e}")
        # Si falla el formato, intentamos devolver la salida cruda convertida a string
        return str(salida_replicate)

def transcribir_sesion(ruta_audio):
    """
    Sube el audio a Replicate usando WHISPER DIARIZATION (Versi√≥n Estable ThomasMol).
    """
    print("üé§ Iniciando transcripci√≥n con detecci√≥n de hablantes...")
    
    try:
        # MODELO: thomasmol/whisper-diarization
        # VERSI√ìN CONFIRMADA: 1495a9cd... (Es la versi√≥n estable m√°s reciente)
        output = replicate.run(
            "thomasmol/whisper-diarization:1495a9cddc83b2203b0d8d3516e38b80fd1572ebc4bc5700ac1da56a9b3ed886",
            input={
                "file": open(ruta_audio, "rb"), # ESTE MODELO USA 'file', NO 'audio'
                "num_speakers": 2,
                "prompt": "Di√°logo de terapia en espa√±ol."
            }
        )
        
        # El modelo devuelve un objeto JSON, lo convertimos a texto plano
        texto_final = formatear_transcripcion(output)
        
        print("‚úÖ Transcripci√≥n completada.")
        return texto_final

    except Exception as e:
        print(f"‚ùå Error en Replicate: {str(e)}")
        raise e

def generar_reporte_clinico(texto_transcrito):
    """
    Env√≠a el texto a DeepSeek V3 para an√°lisis.
    """
    print("üß† Enviando a DeepSeek V3 (Chat) para an√°lisis cl√≠nico...")
    
    prompt_sistema = """
    ACT√öA COMO: Supervisor Cl√≠nico Senior y Experto en Nueva Medicina Germ√°nica (NMG) con capacidad de razonamiento deductivo profundo.

TU OBJETIVO: Generar un informe cl√≠nico y de auditor√≠a basado en el texto proporcionado (que puede ser una transcripci√≥n de sesi√≥n o una consulta escrita).

TIENES PROHIBIDO RESPONDER DE INMEDIATO. Debes realizar el siguiente PROCESO MENTAL INTERNO antes de generar el JSON final:

FASE 1: AN√ÅLISIS PROFUNDO DEL PACIENTE
- Lee todo el texto de manera integral. Identifica el s√≠ntoma f√≠sico exacto y su capa embrionaria (Endodermo, Mesodermo, Ectodermo).
- Detecta la emoci√≥n visceral subyacente (no la que dice el paciente, sino la que siente biol√≥gicamente: miedo a morir, p√©rdida de territorio, separaci√≥n). Usa pistas contextuales.
- Cruza el s√≠ntoma identificado con la Ley de Hierro del C√°ncer para encontrar el Conflicto Biol√≥gico preciso.

FASE 2: AUDITOR√çA DE LA INTERACCI√ìN (EL "OJO CL√çNICO")
- Si hay un terapeuta en el texto: Analiza sus intervenciones. ¬øUs√≥ escucha activa? ¬øIdentific√≥ las pistas clave?
- REFLEXIONA: ¬øEl terapeuta capt√≥ la pista m√°s importante o la dej√≥ pasar?
- BUSCA HUECOS: ¬øEl paciente solt√≥ una frase clave (ej: "desde que muri√≥ mi perro...") que fue ignorada?
- Si es solo una consulta escrita: REFLEXIONA sobre qu√© informaci√≥n falta para completar el cuadro cl√≠nico riguroso.

FASE 3: GENERACI√ìN DE ESTRATEGIA
- Define recomendaciones pr√°cticas espec√≠ficas y ejecutables.
- Sugiere actos de psicomagia relevantes al conflicto biol√≥gico identificado.

---
FORMATO DE SALIDA OBLIGATORIO:
Tu respuesta debe ser UNICAMENTE un objeto JSON v√°lido. NO uses bloques de c√≥digo markdown (```json). Solo el texto plano del JSON.

Estructura del JSON:
{
  "motivo_consulta": "S√≠ntoma o queja principal",
  "emocion_base": "La emoci√≥n biol√≥gica ra√≠z",
  "organo_afectado": "√ìrgano espec√≠fico y capa embrionaria",
  "conflicto_biologico": "Definici√≥n t√©cnica del conflicto",
  "diagnostico_tecnico": "Explicaci√≥n breve basada en las 5 Leyes Biol√≥gicas",
  "hallazgos_clinicos": "Tu reflexi√≥n profunda. Conexiones que la IA detect√≥ entre eventos del pasado y el s√≠ntoma actual.",
  "oportunidades_omitidas": [
      "Lista de pistas que el terapeuta pas√≥ por alto.",
      "Temas que el paciente mencion√≥ y requieren indagaci√≥n profunda.",
      "Preguntas clave que NO se hicieron."
  ],
  "recomendaciones": ["Acci√≥n 1", "Acci√≥n 2"],
  "resumen_sesion": "Resumen ejecutivo de la interacci√≥n."
}
"""

    try:
        response = client.chat.completions.create(
            model="deepseek-chat", # Este modelo apunta autom√°ticamente a DeepSeek-V3
            messages=[
                {"role": "system", "content": prompt_sistema},
                {"role": "user", "content": f"Analiza esta sesi√≥n:\n\n{texto_transcrito}"}
            ],
            stream=False,
            temperature=0.5, # V3 es muy creativo, bajamos la temperatura para asegurar el JSON
            max_tokens=1500
        )
        
        contenido = response.choices[0].message.content
        
        # Limpieza extra por si V3 decide ser amable y poner markdown
        contenido = contenido.replace("```json", "").replace("```", "").strip()
        
        return contenido

    except Exception as e:
        print(f"‚ùå Error en DeepSeek: {str(e)}")
        # Devolvemos un JSON de error v√°lido para que la App no explote
        return """
        {
            "motivo_consulta": "Error en el an√°lisis",
            "emocion_base": "N/A",
            "organo_afectado": "N/A",
            "conflicto_biologico": "Error de conexi√≥n con la IA",
            "diagnostico_tecnico": "No se pudo procesar la solicitud.",
            "recomendaciones": ["Intenta subir el audio nuevamente."],
            "resumen_sesion": "Ocurri√≥ un error t√©cnico."
        }
        """

    try:
        response = client.chat.completions.create(
            model="deepseek-chat",
            messages=[
                {"role": "system", "content": prompt_sistema},
                {"role": "user", "content": f"Analiza esta sesi√≥n:\n\n{texto_transcrito}"}
            ],
            stream=False,
            temperature=0.7
        )
        
        contenido = response.choices[0].message.content
        
        # Limpieza de seguridad por si la IA devuelve bloques de c√≥digo markdown
        contenido = contenido.replace("```json", "").replace("```", "").strip()
        
        return contenido

    except Exception as e:
        print(f"‚ùå Error en DeepSeek: {str(e)}")
        return "Error generando el reporte."
    

    # ACTUALIZACION FORZADA V3 - SOLICITUD DE JSON